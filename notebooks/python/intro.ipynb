{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Goals\n",
    "In our [Principled Data Processing](https://www.youtube.com/watch?v=ZSunU9GQdcI) approach, we want to make our data analysis:\n",
    "- **auditable**\n",
    "     - the result of every task, where possible, can be tested by a different analyst in a different language\n",
    "- **reproducible**\n",
    "     - the same results can be rebuilt by any scientist with the same tools and code\n",
    "- **transparent**\n",
    "     - the result of every task is reviewable\n",
    "- **scalable**\n",
    "     - the task and results are well-suited for \"more than 2\" (datasets used, analysists contributing to codebase, reports written, etc.)\n",
    "\n",
    "There are some specific tools and functions we look for to achieve these characteristics in our code. This notebook is intended to introduce a number of these, provide some context, and stage some examples where possible.\n",
    "\n",
    "_Note: This notebook is formatted as an overview of many python topics, and is not a good example of principled data analysis using Jupyter notebooks. For tips on how to utilize Jupyter notebooks to write python scripts iteratively and quickly, ask Bailey!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolute basics\n",
    "We'll cover a few language-specific pointers here to get up to speed on some python syntax, and then we'll dive in to a few other topics related to principled data processing.\n",
    "\n",
    "If you need more information on python syntax and standard libraries, you're encouraged to ask questions, share code examples, and do a bit of googling. Also, check out:\n",
    "- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)\n",
    "- [the library of python books](https://wiki.python.org/moin/PythonBooks)\n",
    "- [python's built-in types](https://docs.python.org/3/library/stdtypes.html#)\n",
    "- [python's built-in functions](https://docs.python.org/3/library/functions.html)\n",
    "\n",
    "If you want more information on performance of different implementations in python, try:\n",
    "- [scalability.md](https://github.com/HRDAG/training-docs/blob/main/language-tips/python/scalability.md)\n",
    "- [time complexity](https://wiki.python.org/moin/TimeComplexity)\n",
    "- searching for topics related to a specific data structure plus 'documentation', 'time complexity', or 'trade offs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assignment\n",
    "# ints, floats, np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if statements\n",
    "# missing check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loops\n",
    "# 1) build input\n",
    "# 2) filter for a condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list\n",
    "# list comprehension\n",
    "\n",
    "# dict\n",
    "# dict comprehension\n",
    "\n",
    "# set\n",
    "# set comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function declaration\n",
    "# function calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running python scripts\n",
    "You can (and should) run python code as a script from the command line or as a target in a makefile. In order to do this effectively, there are 2 libraries, 1 command, and 1 logic block we can't live without."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### libraries\n",
    "- `argparse` lets us handle arguments provided to the script call in the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `logging` lets us save info to a logfile that we can read later on to answer questions about our data at runtime, without having to reload our data or run the program again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### command\n",
    "- `assert` is a critical command that asks python to assert that something is true before proceeding. This function speaks to our ability to audit the data and be transparent in our approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all() to check columns after shape passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert len(data[col].unique()) == known_unique_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to confirm a manipulation was successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### logic block\n",
    "While we can technically run a .py file that doesn't contain a `if __name__ == '__main__'` block as a script, the instructions we can leave in the `main` block can synthesize our script as a program, and it signals something to the compiler that gives us the ability to pass arguments to the script, so it's an ideal inclusion to your py scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:\t __main__\n",
      "msg:\t Hello world\n"
     ]
    }
   ],
   "source": [
    "# jupyter notebooks run cells as mini-main blocks, so this conditional is always True\n",
    "if __name__ == '__main__':\n",
    "    print('name:\\t', __name__)\n",
    "    print('msg:\\t', 'Hello world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy\n",
    "# - stat methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "# - DataFrame\n",
    "# - Series\n",
    "# - suggested tutorial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
